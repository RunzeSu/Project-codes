# Project_codes_for_DanQ & Transformer

DanQ: original model with bi-LSTM for sequence understanding

transformer: Proposed model with self-attention layer for sequence understanding

transformer_updated: State-of-the-art model(Julian: Upload your codes here if possible)
